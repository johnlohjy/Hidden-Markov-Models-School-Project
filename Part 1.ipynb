{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "493ab2df",
   "metadata": {},
   "source": [
    "# Part 1.1: Write a function that estimates the emission parameters from the training set using MLE (maximum likelihood estimation) (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7de357c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e0d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_emission_parameters_base(training_set):\n",
    "    #Store the count for each state, count(y)\n",
    "    state_count = {}\n",
    "    #Store the state-observation count, count(y->x)\n",
    "    state_observation_count = {}\n",
    "    #Store the estimated emission parameters\n",
    "    estimated_emission_parameters = {}\n",
    "    for i in range(len(training_set)):\n",
    "        #if its not a single empty line that separates sentences\n",
    "        if(len(training_set[i])!=0):\n",
    "            parts = training_set[i].split(\" \")\n",
    "            observation = ' '.join(parts[:len(parts)-1])\n",
    "            state = parts[-1]\n",
    "            \n",
    "            #Increment count(y->x)\n",
    "            if (observation,state) in state_observation_count:\n",
    "                state_observation_count[(observation,state)]+=1\n",
    "            else:\n",
    "                state_observation_count[(observation,state)]=1\n",
    "\n",
    "            #Increment count(y)\n",
    "            if state in state_count:\n",
    "                state_count[state]+=1\n",
    "            else:\n",
    "                state_count[state]=1\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    \n",
    "    #For each x|y, calculate count(y->x)/count(y)\n",
    "    for k,v in state_observation_count.items():\n",
    "        estimated_emission_parameters[k] = v/state_count[k[1]]\n",
    "    \n",
    "    return estimated_emission_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b52e78a",
   "metadata": {},
   "source": [
    "# Part 1.2: Write a function that estimates the emission parameters from the training set using MLE, accounting for words that appear in the test set that do not appear in the training set (maximum likelihood estimation) (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "382e072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_emission_parameters(training_set, k_value=1):\n",
    "    state_count = {}\n",
    "    state_observation_count = {}\n",
    "    estimated_emission_parameters = {}\n",
    "    #Get a set of the trained words\n",
    "    trained_words = set()\n",
    "    \n",
    "    #k_value: k occurences of generating observation #UNK# from any label y\n",
    "    \n",
    "    for i in range(len(training_set)):\n",
    "        #if its not a single empty line that separates sentences\n",
    "        if(len(training_set[i])!=0):\n",
    "            parts = training_set[i].split(\" \")\n",
    "            observation = ' '.join(parts[:len(parts)-1])\n",
    "            state = parts[-1]\n",
    "            \n",
    "            #Increment count(y->x)\n",
    "            if (observation,state) in state_observation_count:\n",
    "                state_observation_count[(observation,state)]+=1\n",
    "            else:\n",
    "                state_observation_count[(observation,state)]=1\n",
    "\n",
    "            #Increment count(y)\n",
    "            if state in state_count:\n",
    "                state_count[state]+=1\n",
    "            else:\n",
    "                state_count[state]=1\n",
    "                \n",
    "            trained_words.add(observation)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    #For each x|y, calculate count(y->x)/(count(y)+k) and calculate k/(count(y)+k) -> the x for this is #UNK#\n",
    "    #We assume from any label y there is a certain chance of generating #UNK# as a rare event,\n",
    "    #and emprically we assume we have observed that there are k occurences of such an event \n",
    "    for k,v in state_observation_count.items():\n",
    "        estimated_emission_parameters[k] = v/(state_count[k[1]]+k_value)\n",
    "        estimated_emission_parameters[(\"#UNK#\",k[1])] = k_value/(state_count[k[1]]+k_value)\n",
    "    \n",
    "    return estimated_emission_parameters, list(trained_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e3051a",
   "metadata": {},
   "source": [
    "# Part 1.3: Implementation of simple sentiment analysis system (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560a1e3d",
   "metadata": {},
   "source": [
    "## Train and Evaluate with ES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55204a9",
   "metadata": {},
   "source": [
    "#### Read ES Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b7f4ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_ES_train = os.path.join(os.getcwd(), 'Data', 'ES', 'train')\n",
    "\n",
    "#Read the file contents\n",
    "with open(filepath_ES_train, 'r', encoding='utf-8') as file:\n",
    "    file_contents_ES_train = file.readlines()\n",
    "    \n",
    "#Convert to training set\n",
    "es_training_set = [w.strip() for w in file_contents_ES_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2b3e42",
   "metadata": {},
   "source": [
    "#### Learn ES parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30e450b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the parameters using the training set\n",
    "all_estimated_emission_parameters, trained_words = estimate_emission_parameters(es_training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d60847",
   "metadata": {},
   "source": [
    "#### Learn ES parameters: Get argmax_y( e(x|y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3aaa0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate y* = argmax_y e(x|y)\n",
    "#i.e. find the y that produces the highest emission probability for x\n",
    "estimated_emission_parameters = {}\n",
    "for k,v in all_estimated_emission_parameters.items():\n",
    "    #If the word is already in the estimated_emission_parameters\n",
    "    if(k[0] in estimated_emission_parameters):\n",
    "        #Check if its emission probability is greater than what has been stored previously\n",
    "        #If it is greater, then update the tag and emission probability \n",
    "        if(v > estimated_emission_parameters[k[0]][1]):\n",
    "            estimated_emission_parameters[k[0]] = [k[1],v]\n",
    "    #else if the word is not already in estimated_emission_parameters\n",
    "    #create an entry\n",
    "    else:\n",
    "        estimated_emission_parameters[k[0]] = [k[1],v]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68647f1",
   "metadata": {},
   "source": [
    "#### Read ES dev.in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afafb8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_ES_devin = os.path.join(os.getcwd(), 'Data', 'ES', 'dev.in')\n",
    "\n",
    "#Read the file contents\n",
    "with open(filepath_ES_devin, 'r', encoding='utf-8') as file:\n",
    "    file_contents_ES_devin = file.readlines()\n",
    "    \n",
    "es_devin = [w.strip() for w in file_contents_ES_devin]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd9caf2",
   "metadata": {},
   "source": [
    "#### Evaluate on ES dev.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d8de77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(es_devin)):\n",
    "    #If its not an empty line\n",
    "    if(len(es_devin[i])!=0):\n",
    "        #If the word can be found in our learned emission parameters, add the learned label\n",
    "        if(es_devin[i] in estimated_emission_parameters.keys()):\n",
    "            es_devin[i] = es_devin[i] + \" \" + estimated_emission_parameters[es_devin[i]][0]\n",
    "        #else, use the label for unknown\n",
    "        else:\n",
    "            es_devin[i] = es_devin[i] + \" \" + estimated_emission_parameters[\"#UNK#\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9428cd72",
   "metadata": {},
   "source": [
    "#### Write to dev.p1.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f47b465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_dev_p1_out = os.path.join(os.getcwd(), 'Data', 'ES', 'dev.p1.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8528f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filepath_dev_p1_out, 'w', encoding='utf-8') as file:\n",
    "    for line in es_devin:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecf2ead",
   "metadata": {},
   "source": [
    "#### Compare dev.p1.out with dev.out for ES"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a63c0867",
   "metadata": {},
   "source": [
    "python evalResult.py dev.out dev.p1.out"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c1e5622",
   "metadata": {},
   "source": [
    "#Entity in gold data: 229\n",
    "#Entity in prediction: 1466\n",
    "\n",
    "#Correct Entity : 178\n",
    "Entity  precision: 0.1214\n",
    "Entity  recall: 0.7773\n",
    "Entity  F: 0.2100\n",
    "\n",
    "#Correct Sentiment : 97\n",
    "Sentiment  precision: 0.0662\n",
    "Sentiment  recall: 0.4236\n",
    "Sentiment  F: 0.1145"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433f7fa0",
   "metadata": {},
   "source": [
    "## Train and Evaluate with RU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6a1655",
   "metadata": {},
   "source": [
    "#### Read RU Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f5351fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_RU_train = os.path.join(os.getcwd(), 'Data', 'RU', 'train')\n",
    "\n",
    "#Read the file contents\n",
    "with open(filepath_RU_train, 'r', encoding='utf-8') as file:\n",
    "    file_contents_RU_train = file.readlines()\n",
    "    \n",
    "#Convert to training set\n",
    "ru_training_set = [w.strip() for w in file_contents_RU_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9148a178",
   "metadata": {},
   "source": [
    "#### Learn RU parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2caa3825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the parameters using the training set\n",
    "all_estimated_emission_parameters, trained_words = estimate_emission_parameters(ru_training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6fb665",
   "metadata": {},
   "source": [
    "#### Learn RU parameters: Get argmax_y( e(x|y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c51e51f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate y* = argmax_y e(x|y)\n",
    "#i.e. find the y that produces the highest emission probability for x\n",
    "estimated_emission_parameters = {}\n",
    "for k,v in all_estimated_emission_parameters.items():\n",
    "    #If the word is already in the estimated_emission_parameters\n",
    "    if(k[0] in estimated_emission_parameters):\n",
    "        #Check if its emission probability is greater than what has been stored previously\n",
    "        #If it is greater, then update the tag and emission probability \n",
    "        if(v > estimated_emission_parameters[k[0]][1]):\n",
    "            estimated_emission_parameters[k[0]] = [k[1],v]\n",
    "    #else if the word is not already in estimated_emission_parameters\n",
    "    #create an entry\n",
    "    else:\n",
    "        estimated_emission_parameters[k[0]] = [k[1],v]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ab81bb",
   "metadata": {},
   "source": [
    "#### Read RU dev.in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e602de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_RU_devin = os.path.join(os.getcwd(), 'Data', 'RU', 'dev.in')\n",
    "\n",
    "#Read the file contents\n",
    "with open(filepath_RU_devin, 'r', encoding='utf-8') as file:\n",
    "    file_contents_RU_devin = file.readlines()\n",
    "    \n",
    "ru_devin = [w.strip() for w in file_contents_RU_devin]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c087cc9a",
   "metadata": {},
   "source": [
    "#### Evaluate on RU dev.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a01f8840",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ru_devin)):\n",
    "    #If its not an empty line\n",
    "    if(len(ru_devin[i])!=0):\n",
    "        #If the word can be found in our learned emission parameters, add the learned label\n",
    "        if(ru_devin[i] in estimated_emission_parameters.keys()):\n",
    "            ru_devin[i] = ru_devin[i] + \" \" + estimated_emission_parameters[ru_devin[i]][0]\n",
    "        #else, use the label for unknown\n",
    "        else:\n",
    "            ru_devin[i] = ru_devin[i] + \" \" + estimated_emission_parameters[\"#UNK#\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20073777",
   "metadata": {},
   "source": [
    "#### Write to dev.p1.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7a7effa",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_dev_p1_out = os.path.join(os.getcwd(), 'Data', 'RU', 'dev.p1.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a8bd930",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filepath_dev_p1_out, 'w', encoding='utf-8') as file:\n",
    "    for line in ru_devin:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e8a7a8",
   "metadata": {},
   "source": [
    "#### Compare dev.p1.out with dev.out for RU"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61182a8d",
   "metadata": {},
   "source": [
    "python evalResult.py dev.out dev.p1.out"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dc34aa5e",
   "metadata": {},
   "source": [
    "#Entity in gold data: 389\n",
    "#Entity in prediction: 1816\n",
    "\n",
    "#Correct Entity : 266\n",
    "Entity  precision: 0.1465\n",
    "Entity  recall: 0.6838\n",
    "Entity  F: 0.2413\n",
    "\n",
    "#Correct Sentiment : 129\n",
    "Sentiment  precision: 0.0710\n",
    "Sentiment  recall: 0.3316\n",
    "Sentiment  F: 0.1170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03ccaff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
